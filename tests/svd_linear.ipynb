{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0, \"../tacotron2/\")\n",
    "sys.path.insert(0, \"../waveglow/\")\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from IPython.display import Audio\n",
    "\n",
    "from audio.vocoders import griffin_lim\n",
    "from tacotron2.model import Tacotron2\n",
    "from tacotron2.text import text_to_sequence, sequence_to_text\n",
    "from waveglow.glow import WaveGlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tacotron 2\n",
    "TACOTRON_CONFIG=json.load(open('../tacotron2/config.json', 'r'))\n",
    "TACOTRON_CHECKPT='../checkpoints/tacotron2_statedict.pt'\n",
    "\n",
    "# Waveglow\n",
    "WAVEGLOW_CONFIG=json.load(open('../waveglow/config.json', 'r'))\n",
    "WAVEGLOW_CHECKPT='../checkpoints/waveglow_256channels_ljs_v3.pt'\n",
    "\n",
    "# Essential\n",
    "ON_GPU=False\n",
    "MAX_WAV_VALUE=32768.0\n",
    "SIGMA=1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2 = Tacotron2(TACOTRON_CONFIG)\n",
    "checkpt_state_dict = torch.load(TACOTRON_CHECKPT,\n",
    "                                map_location=lambda storage, loc: storage)['state_dict']\n",
    "tacotron2.load_state_dict(checkpt_state_dict)\n",
    "_ = tacotron2.cuda().eval() if ON_GPU else tacotron2.cpu().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveglow = torch.load(WAVEGLOW_CHECKPT,\n",
    "                      map_location=lambda storage, loc: storage)['model']\n",
    "waveglow = waveglow.remove_weightnorm(waveglow)\n",
    "_ = waveglow.cuda().eval() if ON_GPU else waveglow.cpu().eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SVD compression of linear layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight\n",
      "encoder.convolutions.0.0.conv.weight\n",
      "encoder.convolutions.0.0.conv.bias\n",
      "encoder.convolutions.0.1.weight\n",
      "encoder.convolutions.0.1.bias\n",
      "encoder.convolutions.0.1.running_mean\n",
      "encoder.convolutions.0.1.running_var\n",
      "encoder.convolutions.0.1.num_batches_tracked\n",
      "encoder.convolutions.1.0.conv.weight\n",
      "encoder.convolutions.1.0.conv.bias\n",
      "encoder.convolutions.1.1.weight\n",
      "encoder.convolutions.1.1.bias\n",
      "encoder.convolutions.1.1.running_mean\n",
      "encoder.convolutions.1.1.running_var\n",
      "encoder.convolutions.1.1.num_batches_tracked\n",
      "encoder.convolutions.2.0.conv.weight\n",
      "encoder.convolutions.2.0.conv.bias\n",
      "encoder.convolutions.2.1.weight\n",
      "encoder.convolutions.2.1.bias\n",
      "encoder.convolutions.2.1.running_mean\n",
      "encoder.convolutions.2.1.running_var\n",
      "encoder.convolutions.2.1.num_batches_tracked\n",
      "encoder.lstm.weight_ih_l0\n",
      "encoder.lstm.weight_hh_l0\n",
      "encoder.lstm.bias_ih_l0\n",
      "encoder.lstm.bias_hh_l0\n",
      "encoder.lstm.weight_ih_l0_reverse\n",
      "encoder.lstm.weight_hh_l0_reverse\n",
      "encoder.lstm.bias_ih_l0_reverse\n",
      "encoder.lstm.bias_hh_l0_reverse\n",
      "decoder.prenet.layers.0.linear_layer.weight\n",
      "decoder.prenet.layers.1.linear_layer.weight\n",
      "decoder.attention_rnn.weight_ih\n",
      "decoder.attention_rnn.weight_hh\n",
      "decoder.attention_rnn.bias_ih\n",
      "decoder.attention_rnn.bias_hh\n",
      "decoder.attention_layer.query_layer.linear_layer.weight\n",
      "decoder.attention_layer.memory_layer.linear_layer.weight\n",
      "decoder.attention_layer.v.linear_layer.weight\n",
      "decoder.attention_layer.location_layer.location_conv.conv.weight\n",
      "decoder.attention_layer.location_layer.location_dense.linear_layer.weight\n",
      "decoder.decoder_rnn.weight_ih\n",
      "decoder.decoder_rnn.weight_hh\n",
      "decoder.decoder_rnn.bias_ih\n",
      "decoder.decoder_rnn.bias_hh\n",
      "decoder.linear_projection.linear_layer.weight\n",
      "decoder.linear_projection.linear_layer.bias\n",
      "decoder.gate_layer.linear_layer.weight\n",
      "decoder.gate_layer.linear_layer.bias\n",
      "postnet.convolutions.0.0.conv.weight\n",
      "postnet.convolutions.0.0.conv.bias\n",
      "postnet.convolutions.0.1.weight\n",
      "postnet.convolutions.0.1.bias\n",
      "postnet.convolutions.0.1.running_mean\n",
      "postnet.convolutions.0.1.running_var\n",
      "postnet.convolutions.0.1.num_batches_tracked\n",
      "postnet.convolutions.1.0.conv.weight\n",
      "postnet.convolutions.1.0.conv.bias\n",
      "postnet.convolutions.1.1.weight\n",
      "postnet.convolutions.1.1.bias\n",
      "postnet.convolutions.1.1.running_mean\n",
      "postnet.convolutions.1.1.running_var\n",
      "postnet.convolutions.1.1.num_batches_tracked\n",
      "postnet.convolutions.2.0.conv.weight\n",
      "postnet.convolutions.2.0.conv.bias\n",
      "postnet.convolutions.2.1.weight\n",
      "postnet.convolutions.2.1.bias\n",
      "postnet.convolutions.2.1.running_mean\n",
      "postnet.convolutions.2.1.running_var\n",
      "postnet.convolutions.2.1.num_batches_tracked\n",
      "postnet.convolutions.3.0.conv.weight\n",
      "postnet.convolutions.3.0.conv.bias\n",
      "postnet.convolutions.3.1.weight\n",
      "postnet.convolutions.3.1.bias\n",
      "postnet.convolutions.3.1.running_mean\n",
      "postnet.convolutions.3.1.running_var\n",
      "postnet.convolutions.3.1.num_batches_tracked\n",
      "postnet.convolutions.4.0.conv.weight\n",
      "postnet.convolutions.4.0.conv.bias\n",
      "postnet.convolutions.4.1.weight\n",
      "postnet.convolutions.4.1.bias\n",
      "postnet.convolutions.4.1.running_mean\n",
      "postnet.convolutions.4.1.running_var\n",
      "postnet.convolutions.4.1.num_batches_tracked\n"
     ]
    }
   ],
   "source": [
    "for key in tacotron2.state_dict().keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Inference**\n",
    "**Prepare texts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"Cristiano Ronaldo has won his first UEFA Champions League with Manchester United in two thousand eight.\",\n",
    "         \"Implicit learning of the likelihood makes normalizing flows very strong generative tool.\",\n",
    "         \"WaveGlow and L P C Net are accelerated derivatives of WaveNet state-of-the-art model.\"]\n",
    "assert len(texts) > 0\n",
    "texts = [text.strip() for text in texts]\n",
    "sequences = [np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "             for text in texts]\n",
    "sequences = [torch.autograd.Variable(torch.from_numpy(sequence)).long()\n",
    "             for sequence in sequences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Synthesis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_IDX = -1\n",
    "print(sequence_to_text(map(int, list(sequences[TEXT_IDX].squeeze()))))\n",
    "\n",
    "total_start = datetime.now()\n",
    "\n",
    "with torch.no_grad():\n",
    "    tc_start = datetime.now()\n",
    "    mel_outputs, mel, gate_outputs, alignments = tacotron2.inference(sequences[TEXT_IDX])\n",
    "    tc_end = datetime.now()\n",
    "    \n",
    "    wg_start = datetime.now()\n",
    "    wave = MAX_WAV_VALUE*waveglow.infer(mel, sigma=SIGMA)\n",
    "    wg_end = datetime.now()\n",
    "    \n",
    "total_end = datetime.now()\n",
    "print('Total inference time:', total_end - total_start)\n",
    "print('Tacotron 2 inference time:', tc_end - tc_start)\n",
    "print('Waveglow inference time:', wg_end - wg_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(wave, rate=22050)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
